{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading the MNIST dataset in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The compilation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)\n",
    "print(train_labels.dtype)\n",
    "print(test_images.dtype)\n",
    "print(test_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**\"Fitting\" the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.4364\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1195\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0712\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0491\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x177c9eeb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the model to make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.2887610e-08, 8.6152596e-09, 1.0230323e-05, 4.3237582e-05,\n",
       "       9.8606616e-11, 1.9645788e-07, 4.1821108e-12, 9.9993503e-01,\n",
       "       2.7052405e-07, 1.0806663e-05], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998740928876"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99993503"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Evaluating the model on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9785 - loss: 0.0705\n",
      "test_acc: 0.9818000197410583\n",
      "test_loss: 0.058986976742744446\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")\n",
    "print(f\"test_loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([12])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10 246\n",
      "-9 247\n",
      "-8 248\n",
      "-7 249\n",
      "-6 250\n",
      "-5 251\n",
      "-4 252\n",
      "-3 253\n",
      "-2 254\n",
      "-1 255\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "30 30\n",
      "31 31\n",
      "32 32\n",
      "33 33\n",
      "34 34\n",
      "35 35\n",
      "36 36\n",
      "37 37\n",
      "38 38\n",
      "39 39\n",
      "40 40\n",
      "41 41\n",
      "42 42\n",
      "43 43\n",
      "44 44\n",
      "45 45\n",
      "46 46\n",
      "47 47\n",
      "48 48\n",
      "49 49\n",
      "50 50\n",
      "51 51\n",
      "52 52\n",
      "53 53\n",
      "54 54\n",
      "55 55\n",
      "56 56\n",
      "57 57\n",
      "58 58\n",
      "59 59\n",
      "60 60\n",
      "61 61\n",
      "62 62\n",
      "63 63\n",
      "64 64\n",
      "65 65\n",
      "66 66\n",
      "67 67\n",
      "68 68\n",
      "69 69\n",
      "70 70\n",
      "71 71\n",
      "72 72\n",
      "73 73\n",
      "74 74\n",
      "75 75\n",
      "76 76\n",
      "77 77\n",
      "78 78\n",
      "79 79\n",
      "80 80\n",
      "81 81\n",
      "82 82\n",
      "83 83\n",
      "84 84\n",
      "85 85\n",
      "86 86\n",
      "87 87\n",
      "88 88\n",
      "89 89\n",
      "90 90\n",
      "91 91\n",
      "92 92\n",
      "93 93\n",
      "94 94\n",
      "95 95\n",
      "96 96\n",
      "97 97\n",
      "98 98\n",
      "99 99\n",
      "100 100\n",
      "101 101\n",
      "102 102\n",
      "103 103\n",
      "104 104\n",
      "105 105\n",
      "106 106\n",
      "107 107\n",
      "108 108\n",
      "109 109\n",
      "110 110\n",
      "111 111\n",
      "112 112\n",
      "113 113\n",
      "114 114\n",
      "115 115\n",
      "116 116\n",
      "117 117\n",
      "118 118\n",
      "119 119\n",
      "120 120\n",
      "121 121\n",
      "122 122\n",
      "123 123\n",
      "124 124\n",
      "125 125\n",
      "126 126\n",
      "127 127\n",
      "128 128\n",
      "129 129\n",
      "130 130\n",
      "131 131\n",
      "132 132\n",
      "133 133\n",
      "134 134\n",
      "135 135\n",
      "136 136\n",
      "137 137\n",
      "138 138\n",
      "139 139\n",
      "140 140\n",
      "141 141\n",
      "142 142\n",
      "143 143\n",
      "144 144\n",
      "145 145\n",
      "146 146\n",
      "147 147\n",
      "148 148\n",
      "149 149\n",
      "150 150\n",
      "151 151\n",
      "152 152\n",
      "153 153\n",
      "154 154\n",
      "155 155\n",
      "156 156\n",
      "157 157\n",
      "158 158\n",
      "159 159\n",
      "160 160\n",
      "161 161\n",
      "162 162\n",
      "163 163\n",
      "164 164\n",
      "165 165\n",
      "166 166\n",
      "167 167\n",
      "168 168\n",
      "169 169\n",
      "170 170\n",
      "171 171\n",
      "172 172\n",
      "173 173\n",
      "174 174\n",
      "175 175\n",
      "176 176\n",
      "177 177\n",
      "178 178\n",
      "179 179\n",
      "180 180\n",
      "181 181\n",
      "182 182\n",
      "183 183\n",
      "184 184\n",
      "185 185\n",
      "186 186\n",
      "187 187\n",
      "188 188\n",
      "189 189\n",
      "190 190\n",
      "191 191\n",
      "192 192\n",
      "193 193\n",
      "194 194\n",
      "195 195\n",
      "196 196\n",
      "197 197\n",
      "198 198\n",
      "199 199\n",
      "200 200\n",
      "201 201\n",
      "202 202\n",
      "203 203\n",
      "204 204\n",
      "205 205\n",
      "206 206\n",
      "207 207\n",
      "208 208\n",
      "209 209\n",
      "210 210\n",
      "211 211\n",
      "212 212\n",
      "213 213\n",
      "214 214\n",
      "215 215\n",
      "216 216\n",
      "217 217\n",
      "218 218\n",
      "219 219\n",
      "220 220\n",
      "221 221\n",
      "222 222\n",
      "223 223\n",
      "224 224\n",
      "225 225\n",
      "226 226\n",
      "227 227\n",
      "228 228\n",
      "229 229\n",
      "230 230\n",
      "231 231\n",
      "232 232\n",
      "233 233\n",
      "234 234\n",
      "235 235\n",
      "236 236\n",
      "237 237\n",
      "238 238\n",
      "239 239\n",
      "240 240\n",
      "241 241\n",
      "242 242\n",
      "243 243\n",
      "244 244\n",
      "245 245\n",
      "246 246\n",
      "247 247\n",
      "248 248\n",
      "249 249\n",
      "250 250\n",
      "251 251\n",
      "252 252\n",
      "253 253\n",
      "254 254\n",
      "255 255\n",
      "256 0\n",
      "257 1\n",
      "258 2\n",
      "259 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(-10, 260):\n",
    "    x = np.array(i).astype('uint8')\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "106168320*32 / 8 /1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.81 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30973411, 0.44400758, 0.05109061, 0.14116149, 0.03746476,\n",
       "       0.84424714, 0.86641338, 0.03037304, 0.76740345, 0.52773677])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A geometric interpretation of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### What's a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Derivative of a tensor operation: the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Chaining derivatives: The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[0.7618412, 0.8819734],\n",
       "       [0.9249972, 0.9912052]], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(tf.random.uniform((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(tf.zeros((2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[0.10262883, 0.7472724 ],\n",
      "       [0.96188915, 0.24840689]], dtype=float32)>\n",
      "b: <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
      "x: tf.Tensor(\n",
      "[[0.6249373  0.98303676]\n",
      " [0.7631744  0.26778543]], shape=(2, 2), dtype=float32)\n",
      "y: tf.Tensor(\n",
      "[[1.009709   0.7111915 ]\n",
      " [0.33590358 0.6368189 ]], shape=(2, 2), dtype=float32)\n",
      "grad: [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1.3881117, 1.3881117],\n",
      "       [1.2508222, 1.2508222]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "print('W:', W)\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "print('b:', b)\n",
    "x = tf.random.uniform((2, 2))\n",
    "print('x:', x)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "print('y:', y)\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
    "print('grad:', grad_of_y_wrt_W_and_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.60797406"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6249373 + 0.98303676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.4476\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1156\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0736\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0504\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17aa59490>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Dense class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Running one training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 5.93\n",
      "loss at batch 100: 2.23\n",
      "loss at batch 200: 2.20\n",
      "loss at batch 300: 2.07\n",
      "loss at batch 400: 2.19\n",
      "Epoch 1\n",
      "loss at batch 0: 1.90\n",
      "loss at batch 100: 1.88\n",
      "loss at batch 200: 1.83\n",
      "loss at batch 300: 1.70\n",
      "loss at batch 400: 1.82\n",
      "Epoch 2\n",
      "loss at batch 0: 1.58\n",
      "loss at batch 100: 1.58\n",
      "loss at batch 200: 1.51\n",
      "loss at batch 300: 1.41\n",
      "loss at batch 400: 1.50\n",
      "Epoch 3\n",
      "loss at batch 0: 1.33\n",
      "loss at batch 100: 1.34\n",
      "loss at batch 200: 1.25\n",
      "loss at batch 300: 1.20\n",
      "loss at batch 400: 1.27\n",
      "Epoch 4\n",
      "loss at batch 0: 1.13\n",
      "loss at batch 100: 1.16\n",
      "loss at batch 200: 1.05\n",
      "loss at batch 300: 1.04\n",
      "loss at batch 400: 1.10\n",
      "Epoch 5\n",
      "loss at batch 0: 0.98\n",
      "loss at batch 100: 1.03\n",
      "loss at batch 200: 0.91\n",
      "loss at batch 300: 0.92\n",
      "loss at batch 400: 0.98\n",
      "Epoch 6\n",
      "loss at batch 0: 0.87\n",
      "loss at batch 100: 0.92\n",
      "loss at batch 200: 0.80\n",
      "loss at batch 300: 0.83\n",
      "loss at batch 400: 0.89\n",
      "Epoch 7\n",
      "loss at batch 0: 0.79\n",
      "loss at batch 100: 0.84\n",
      "loss at batch 200: 0.72\n",
      "loss at batch 300: 0.76\n",
      "loss at batch 400: 0.82\n",
      "Epoch 8\n",
      "loss at batch 0: 0.73\n",
      "loss at batch 100: 0.77\n",
      "loss at batch 200: 0.66\n",
      "loss at batch 300: 0.70\n",
      "loss at batch 400: 0.77\n",
      "Epoch 9\n",
      "loss at batch 0: 0.67\n",
      "loss at batch 100: 0.72\n",
      "loss at batch 200: 0.61\n",
      "loss at batch 300: 0.66\n",
      "loss at batch 400: 0.73\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
